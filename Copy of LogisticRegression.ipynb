{"cells":[{"cell_type":"markdown","metadata":{"id":"Ek1sl_oJipXv"},"source":["# Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"XCIMyLnWipX1"},"source":["Logistic Regression Cost Function\n","\n","$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} [-y^{(i)}\\log (h_\\theta(x^{(i)})) - (1-y^{(i)})\\log (1-h_\\theta(x^{(i)})]\n","$$"]},{"cell_type":"markdown","metadata":{"id":"-rbhhlzWipX1"},"source":["Gradient decent"]},{"cell_type":"markdown","metadata":{"id":"2sfs_ByOipX2"},"source":["\n","Want $ \\min_\\theta J(\\theta): $\n","    \n","Repeat   {\n","    $$ \\theta_j :=  \\theta_j  - \\alpha \\sum_{i=1}^{m} h_\\theta(x^{(i)} - y^{(i)}) x_j^{(i)} $$\n","    (simultaneously update all $\\theta_j$)\n","    \n","}\n","    "]},{"cell_type":"markdown","metadata":{"id":"NBYfjyg_ipX2"},"source":["$$ h_\\theta(x) = \\frac{1}{1+ e^{-\\theta^T{x}} } $$"]},{"cell_type":"markdown","metadata":{"id":"3m83plXyipX3"},"source":["Vectorized implementation: \n","    $$h = g(H\\theta)$$"]},{"cell_type":"markdown","metadata":{"id":"lO_pHBYYipX3"},"source":["$$J(\\theta) = \\frac{1}{m} (-y^T \\log(h) - (1-y)^T \\log(1-h))$$"]},{"cell_type":"markdown","metadata":{"id":"Pnb5_4xJipX4"},"source":["$$ \\theta := \\theta - \\frac{\\alpha}{m} X^T (g(X\\theta) - \\overrightarrow{y}) $$"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ar-FKA_3ipX4","executionInfo":{"status":"ok","timestamp":1662352579236,"user_tz":-330,"elapsed":694,"user":{"displayName":"PRATYAY","userId":"17115142085867693805"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math\n","from  scipy.optimize import minimize as opt\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KhBrRmtJipX6"},"outputs":[],"source":["data = pd.read_csv('ex2data2.txt', header = None)\n","data = np.array(data)\n","X = data[:, [0,1]] \n","y = data[:, [2]]"]},{"cell_type":"markdown","metadata":{"id":"wA_JiSzqipX7"},"source":["# Sigmoid function"]},{"cell_type":"markdown","metadata":{"id":"Nx4VcJPEipX8"},"source":["$$ g(z) = \\frac{1}{1+ e^{-z}} $$\n"]},{"cell_type":"markdown","metadata":{"id":"d6c8KJpTipX8"},"source":[" $$h_\\theta(x)= g(\\theta^T x) $$"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"WB80tLsUipX9","executionInfo":{"status":"ok","timestamp":1662352588758,"user_tz":-330,"elapsed":368,"user":{"displayName":"PRATYAY","userId":"17115142085867693805"}}},"outputs":[],"source":["def g(z):\n","    sigm = 1.0/(1.0+np.exp(-z))\n","    return sigm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V573n8jFipX-"},"outputs":[],"source":["X = np.insert(X, 0, values=1, axis=1)\n","theta = np.zeros((X.shape[1],1))"]},{"cell_type":"markdown","metadata":{"id":"5k5j8lAQipX-"},"source":["# Cost function and gradient"]},{"cell_type":"markdown","metadata":{"id":"15OEZSLzipX_"},"source":["Logistic Regression Cost Function\n","\n","\n","$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} [-y^{(i)}\\log (h_\\theta(x^{(i)})) - (1-y^{(i)})\\log (1-h_\\theta(x^{(i)}))]\n","$$"]},{"cell_type":"markdown","metadata":{"id":"hgpQOZ20ipX_"},"source":["Vectorized implementation: \n","    $$h = g(H\\theta)$$"]},{"cell_type":"markdown","metadata":{"id":"_Apx_QPwipX_"},"source":["$$J(\\theta) = \\frac{1}{m} (-y^T \\log(h) - (1-y)^T \\log(1-h))$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KNJ2y91zipYA"},"outputs":[],"source":["in_theta = np.zeros((X.shape[1],1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggOlQftfipYA"},"outputs":[],"source":["def costFunction(theta, x, y):   \n","    m = len(y)\n","    h_theta = g(x.dot(theta))\n","    J = (1.0/m)* (((-y).transpose()).dot(np.log(h_theta)) - (1.0 -y.transpose()).dot(np.log(1.0-h_theta)))\n","    grad = grad = (1.0/m)* x.transpose().dot(h_theta - y)    \n","    #return J, grad\n","    print(\"Cost at theta:\", str(J[0,0]))\n","    print(\"Gradient at theta:\",\"\\n\", str(grad[0,0]),\"\\n\", str(grad[1,0]),\"\\n\", str(grad[2,0]))\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0X0wetpZipYA","executionInfo":{"status":"ok","timestamp":1662113537189,"user_tz":-330,"elapsed":33,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"928dd293-b982-4d21-e311-b0647b2a1f26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cost at theta: 0.6931471805599454\n","Gradient at theta: \n"," 0.00847457627118644 \n"," 0.01878809322033896 \n"," 7.777118644067507e-05\n"]}],"source":["costFunction(in_theta, X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXL37n3hipYB"},"outputs":[],"source":["test_theta= np.array([[-24], [0.2], [0.2]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQB3o86BipYB","executionInfo":{"status":"ok","timestamp":1662113537189,"user_tz":-330,"elapsed":27,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b9b13cf-27c1-4653-9ef2-a826bc1b8426"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cost at theta: 11.776595295633161\n","Gradient at theta: \n"," -0.4915254236888716 \n"," -0.008601361013087979 \n"," -0.09147300846541176\n"]}],"source":["costFunction(test_theta, X, y)"]},{"cell_type":"markdown","metadata":{"id":"vBsYc2DwipYB"},"source":["# Optimizing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWeTdEjcipYC"},"outputs":[],"source":["def CostFunction(theta, x, y):\n","    m = len(y)\n","    h_theta = g(x.dot(theta))\n","    J = (1.0/m)* (((-y).transpose()).dot(np.log(h_theta)) - (1.0 -y.transpose()).dot(np.log(1.0-h_theta)))\n","    J = np.float64(J)\n","    return J"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wRNlYzXipYC"},"outputs":[],"source":[" def Gradient(theta, x, y):\n","    m = len(y)\n","    n = x.shape[1]\n","    theta = theta.reshape((n,1))\n","    h_theta = g(x.dot(theta))\n","    grad = (1.0/m)* (x.transpose().dot(h_theta - y)) \n","    return grad.flatten()   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rn05R6QLipYC","executionInfo":{"status":"ok","timestamp":1662113537190,"user_tz":-330,"elapsed":25,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b548ae51-d5f7-45a5-d1a8-06f09d94c989"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cost at theta: 0.690241122092821 \n"," Theta: [-0.01418037 -0.30356918 -0.01812411]\n"]}],"source":["Result = opt(fun = CostFunction, x0 = in_theta, args = (X, y), method = 'TNC', jac = Gradient, options ={'maxiter':400})\n","theta = Result.x\n","print('Cost at theta:',Result.fun, '\\n', 'Theta:', Result.x)"]},{"cell_type":"markdown","metadata":{"id":"CTZ8azr6ipYC"},"source":["# Evaluating logistic regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ci6Z4YctipYD","executionInfo":{"status":"ok","timestamp":1662113537191,"user_tz":-330,"elapsed":25,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"29338e48-e779-4823-8768-c4fae6f371e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["For a student with score 45 on exam 1\n"," and score 85 on exam 2 we predict an admission probability of  2.4663816721989776e-07\n"]}],"source":["prob = g(np.array([1, 45, 85]).dot(theta))\n","print('For a student with score 45 on exam 1\\n and score 85 on exam 2 we predict an admission probability of ', prob)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-C_kvOZGipYD"},"outputs":[],"source":["def predict(theta, x):    \n","    m = X.shape[0]\n","    p = np.zeros((m,1))\n","    n = X.shape[1]\n","    theta = theta.reshape((n,1))\n","    h_theta = g(X.dot(theta))    \n","    for i in range(0, h_theta.shape[0]):\n","        if h_theta[i] > 0.5:\n","            p[i, 0] = 1\n","        else:\n","            p[i, 0] = 0\n","    return p"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6CjRTR9XipYD","executionInfo":{"status":"ok","timestamp":1662113537191,"user_tz":-330,"elapsed":23,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f88327b9-eec0-487c-c34a-36d4e50e008f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Accuracy: 55.08474576271186\n"]}],"source":["p = predict(theta, X)\n","print ('Train Accuracy:', (y[p == y].size / float(y.size)) * 100.0)"]},{"cell_type":"markdown","metadata":{"id":"h71e3yUnipYE"},"source":["# Regularized logistic regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pcp2FQ_CipYE"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math\n","from  scipy.optimize import minimize as opt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmPZHR7jipYE"},"outputs":[],"source":["data = pd.read_csv('ex2data2.txt', header = None)\n","data = np.array(data)\n","X = data[:, [0,1]] \n","y = data[:, [2]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lonwNrDuipYE"},"outputs":[],"source":["x_size = X[:,0].shape[0]\n","\n","X1 = X[:,0]\n","X1 = X1.reshape(x_size, 1)\n","\n","X2 = X[:,1]\n","X2 = X2.reshape(x_size, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WocQT-JRipYF"},"outputs":[],"source":["def mapFeature(X1, X2):\n","    degree = 6\n","    out = np.ones((X1.shape[0], 1))\n","    for i in range(1, degree+1):\n","        for j in range (0, i+1):\n","            out1 = np.power(X1, (i-j))\n","            out2 = np.power(X2, j)\n","            out = np.concatenate((out,out1*out2),axis=1)\n","       \n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjBTFfWRipYF"},"outputs":[],"source":["X = mapFeature(X1, X2)"]},{"cell_type":"markdown","metadata":{"id":"QTCa_WuZipYF"},"source":["# Regularized Cost function and Gradient"]},{"cell_type":"markdown","metadata":{"id":"5cSX2f7hipYF"},"source":["Regularized Logistic Regression Cost Function\n","\n","\n","$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} [-y^{(i)}\\log (h_\\theta(x^{(i)})) - (1-y^{(i)})\\log (1-h_\\theta(x^{(i)}))] +  \\frac{\\lambda}{2m}\\sum_{j=1}^{n} \\theta_j^2\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOwv3-hNipYF"},"outputs":[],"source":["in_theta = np.zeros((X.shape[1],1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxGFLRCXipYF"},"outputs":[],"source":["lamb = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yF8N__ZnipYG"},"outputs":[],"source":["def g(z):\n","    sigm = 1.0/(1.0+np.exp(-z))\n","    return sigm\n","\n","def CostFunction(theta, x, y):\n","    m = len(y)\n","    h_theta = g(x.dot(theta))\n","    J = (1.0/m)* (((-y).transpose()).dot(np.log(h_theta)) - (1.0 -y.transpose()).dot(np.log(1.0-h_theta)))\n","    J = np.float64(J)\n","    return J\n","\n","def Gradient(theta, x, y):\n","    m = len(y)\n","    n = x.shape[1]\n","    theta = theta.reshape((n,1))\n","    h_theta = g(x.dot(theta))\n","    grad = (1.0/m)* (x.transpose().dot(h_theta - y))\n","    return grad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fzsUNh_SipYG"},"outputs":[],"source":["def costFunctionReg(theta, x, y, lamb):\n","    m = len(y)\n","    J = CostFunction(theta, x, y)\n","    sum_theta = (theta[1:]**2).sum()\n","    J = J +lamb/(2*m)*sum_theta\n","    return J\n","\n","def GradReg(theta, x, y, lamb):\n","    m = len(y)\n","    n = x.shape[1]\n","    theta = theta.reshape((n,1))\n","    grad = Gradient(theta, X, y)\n","    grad[1:,:] =grad[1:,:]+(lamb/m)*theta[1:,:]\n","    return grad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkmrrK4bipYG","executionInfo":{"status":"ok","timestamp":1662113537776,"user_tz":-330,"elapsed":20,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"outputId":"bc3ba606-7bdd-4692-df1b-206e31fdba20","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["('Cost at initial theta (zeros):', 0.6931471805599454, '\\n', 'Gradient at initial theta (zeros) - first five values only:', array([[8.47457627e-03],\n","       [1.87880932e-02],\n","       [7.77711864e-05],\n","       [5.03446395e-02],\n","       [1.15013308e-02]]))\n"]}],"source":["cost = costFunctionReg(in_theta, X, y, lamb)\n","grad = GradReg(in_theta, X, y, lamb)\n","print (('Cost at initial theta (zeros):', cost, '\\n', 'Gradient at initial theta (zeros) - first five values only:', grad[:5]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pjUpfWzipYG"},"outputs":[],"source":["test_theta = np.ones((X.shape[1],1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_CZYhJ9yipYG","executionInfo":{"status":"ok","timestamp":1662113537778,"user_tz":-330,"elapsed":18,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"23eba250-69e9-430d-e0c5-512df1a419c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cost at test theta: 2.02044153500484 \n"," Gradient at test theta - first five values only: [[0.34604507]\n"," [0.07660616]\n"," [0.11004999]\n"," [0.14211702]\n"," [0.00743991]]\n"]}],"source":["cost = CostFunction(test_theta, X, y)\n","grad = Gradient(test_theta, X, y)\n","print ('Cost at test theta:', cost, '\\n', 'Gradient at test theta - first five values only:', grad[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgDLz2YmipYH","executionInfo":{"status":"ok","timestamp":1662113537778,"user_tz":-330,"elapsed":17,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"21e953b4-db40-4bdb-e240-906a39e72cfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cost at theta: 0.6482157019663689 \n"," Theta: [ 0.32613879 -0.0081937   0.16579705 -0.44664536 -0.11177353 -0.27890096\n"," -0.07142123 -0.05788414 -0.06509849 -0.10636843 -0.33671549 -0.01295009\n"," -0.11670601 -0.02808898 -0.2860233  -0.11615744 -0.03705555 -0.02241237\n"," -0.04887209 -0.04163238 -0.18676627 -0.25334294 -0.00291817 -0.05796983\n"," -0.00053332 -0.06353213 -0.01207366 -0.27150097]\n"]}],"source":["Result = opt(fun = costFunctionReg, x0 = in_theta, args = (X, y, lamb), method = 'TNC', jac = GradReg, options ={'maxiter':400})\n","theta = Result.x\n","print('Cost at theta:',Result.fun, '\\n', 'Theta:', theta)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBGQS4ymipYH"},"outputs":[],"source":["def predict(theta, x): \n","    m = X.shape[0]\n","    p = np.zeros((m,1))\n","    n = X.shape[1]\n","    theta = theta.reshape((n,1))\n","    h_theta = g(X.dot(theta))\n","    for i in range(0, h_theta.shape[0]):\n","        if h_theta[i] > 0.5:\n","            p[i, 0] = 1\n","        else:\n","            p[i, 0] = 0\n","    return p"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cd3MZp-MipYH","executionInfo":{"status":"ok","timestamp":1662113537779,"user_tz":-330,"elapsed":15,"user":{"displayName":"DEBASMIT","userId":"13571278386438872670"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0cefd23-7315-4271-cc2b-bcc1a493a4fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Accuracy: 74.57627118644068\n"]}],"source":["p = predict(theta, X)\n","print ('Train Accuracy:', (y[p == y].size / float(y.size)) * 100.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B359KagMipYH"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}